
import os
import pickle
import json

# # %%
# path = os.getcwd()

# %%
path='/home/mdrahman/Desktop/513/VulDet/data/D2A'

# %%
def get_file_path(parent_path, key='extractor_0'):
    if os.path.isfile(parent_path):
        if parent_path.split(".")[-1] == 'pickle' and  key in parent_path:
            return [parent_path]
        return []
    result = []
    for file_dir in os.listdir(parent_path):
        result += get_file_path(os.path.join(parent_path, file_dir), key)
    return result


# %%
log = False
def read_file(file_path):
    global log
    f = open(file_path, 'rb')
    data = []
    # data = pickle.load(f)
    while True:
        try:
            data_ = pickle.load(f)
            data_json = {
                'id': data_['id'],
                'label': data_['label'],
                'project': data_['project'],
                'bug_type': data_['bug_type'],
                'label_source': data_['label_source'],
                'line': data_['bug_info']['line'],
                'column': data_['bug_info']['column'],
                'name': data_['bug_info']['procedure'],
                'file': data_['bug_info']['file'],
            }
            flag = False
            for key, value in data_['functions'].items():
                if value['file'] == data_['bug_info']['file'] and value['name'] == data_['bug_info']['procedure']:
                    data_json['function'] = value['code']
                    data_json['loc']: value['loc']
                    flag = True
                    break
            # if not flag and not log:
            #     log = True
            #     print(data_['functions'])
            #     break
            data.append(data_json)
        except EOFError:
            break
    return data 

# %%
result = {}
for dir_ in os.listdir(path):
    if dir_[-3:] == '.gz' or dir_ in ['csvs', 'split', 'jsonl']:
        continue

    dir__ = os.path.join(path, dir_)
    extractor = get_file_path(dir__, key='extractor_0')
    if len(extractor) == 0:
        continue
    label_0 = get_file_path(dir__, key='labeler_0')
    label_1 = get_file_path(dir__, key='labeler_1')
    label_1_data = read_file(label_1[0])
    label_0_data = read_file(label_0[0])
    result[dir_] = {
        'label_0': label_0_data,
        'label_1': label_1_data,
    }
    print(dir_, len(label_0_data), len(label_1_data))


    

# %%
def read_file_extractor(file_path, label_1):
    map_id = {}
    for data_ in label_1:
        idx = data_['id'][:-1] + '0'
        map_id[idx] = {
            'file': data_['file'],
            'name': data_['name'],
        }
    f = open(file_path, 'rb')
    data = []
    # data_ = pickle.load(f)
    cnt = 0
    while True:
        try:
            data_ = pickle.load(f)
            data_json = {
                'id': data_['id'],
                'label': data_['label'],
                'project': data_['project'],
                'bug_type': data_['bug_type'],
                'label_source': data_['label_source'],
            }

            for key, value in data_['functions'].items():
                if value['file'] == map_id[data_['id']]['file'] and value['name'] == map_id[data_['id']]['name']:
                    data_json['function'] = value['code']
                    break
            data.append(data_json)
        except EOFError:
            break
    return data

# %%

for dir_ in os.listdir(path):
    if dir_[-3:] == '.gz' or dir_ in ['csvs', 'split']:
        continue
    dir__ = os.path.join(path, dir_)
    extractor = get_file_path(dir__, key='extractor_0')
    if len(extractor) == 0:
        continue
    label_0 = get_file_path(dir__, key='labeler_0')
    label_1 = get_file_path(dir__, key='labeler_1')
    
    extractor_data = read_file_extractor(extractor[0], result[dir_]['label_1'])
    result[dir_]['extractor_0'] = extractor_data
    print(dir_, len(extractor_data))


    

# %%
def write_to_jsonl(folder_path, file_name, data_):
    file_path = os.path.join(folder_path, file_name)
    f = open(file_path, 'w')
    f.writelines([json.dumps(da)+"\n"  for da in data_])
    f.close()

# %%
for dir_ in ["libtiff", "httpd", "ffmpeg", "nginx", "openssl", "libav"]:
    next_path = os.path.join(path, 'jsonl', dir_)
    if not os.path.exists(next_path):
        os.makedirs(next_path)
    write_to_jsonl(next_path, 'extractor_0.jsonl', result[dir_]['extractor_0'])
    write_to_jsonl(next_path, 'labeler_0.jsonl', result[dir_]['label_0'])
    write_to_jsonl(next_path, 'labeler_1.jsonl', result[dir_]['label_1'])


