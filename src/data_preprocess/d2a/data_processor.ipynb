{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mdrahman/Desktop/513/VulDet/data/D2A'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='/home/mdrahman/Desktop/513/VulDet/data/D2A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_path(parent_path, key='extractor_0'):\n",
    "    if os.path.isfile(parent_path):\n",
    "        if parent_path.split(\".\")[-1] == 'pickle' and  key in parent_path:\n",
    "            return [parent_path]\n",
    "        return []\n",
    "    result = []\n",
    "    for file_dir in os.listdir(parent_path):\n",
    "        result += get_file_path(os.path.join(parent_path, file_dir), key)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = False\n",
    "def read_file(file_path):\n",
    "    global log\n",
    "    f = open(file_path, 'rb')\n",
    "    data = []\n",
    "    # data = pickle.load(f)\n",
    "    while True:\n",
    "        try:\n",
    "            data_ = pickle.load(f)\n",
    "            data_json = {\n",
    "                'id': data_['id'],\n",
    "                'label': data_['label'],\n",
    "                'project': data_['project'],\n",
    "                'bug_type': data_['bug_type'],\n",
    "                'label_source': data_['label_source'],\n",
    "                'line': data_['bug_info']['line'],\n",
    "                'column': data_['bug_info']['column'],\n",
    "                'name': data_['bug_info']['procedure'],\n",
    "                'file': data_['bug_info']['file'],\n",
    "            }\n",
    "            flag = False\n",
    "            for key, value in data_['functions'].items():\n",
    "                if value['file'] == data_['bug_info']['file'] and value['name'] == data_['bug_info']['procedure']:\n",
    "                    data_json['function'] = value['code']\n",
    "                    data_json['loc']: value['loc']\n",
    "                    flag = True\n",
    "                    break\n",
    "            # if not flag and not log:\n",
    "            #     log = True\n",
    "            #     print(data_['functions'])\n",
    "            #     break\n",
    "            data.append(data_json)\n",
    "        except EOFError:\n",
    "            break\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nginx 17945 421\n",
      "openssl 343148 8022\n",
      "ffmpeg 654891 4826\n",
      "libtiff 12096 553\n",
      "libav 236415 4614\n",
      "httpd 12475 217\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "for dir_ in os.listdir(path):\n",
    "    if dir_[-3:] == '.gz' or dir_ in ['csvs', 'split', 'jsonl']:\n",
    "        continue\n",
    "\n",
    "    dir__ = os.path.join(path, dir_)\n",
    "    extractor = get_file_path(dir__, key='extractor_0')\n",
    "    if len(extractor) == 0:\n",
    "        continue\n",
    "    label_0 = get_file_path(dir__, key='labeler_0')\n",
    "    label_1 = get_file_path(dir__, key='labeler_1')\n",
    "    label_1_data = read_file(label_1[0])\n",
    "    label_0_data = read_file(label_0[0])\n",
    "    result[dir_] = {\n",
    "        'label_0': label_0_data,\n",
    "        'label_1': label_1_data,\n",
    "    }\n",
    "    print(dir_, len(label_0_data), len(label_1_data))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_extractor(file_path, label_1):\n",
    "    map_id = {}\n",
    "    for data_ in label_1:\n",
    "        idx = data_['id'][:-1] + '0'\n",
    "        map_id[idx] = {\n",
    "            'file': data_['file'],\n",
    "            'name': data_['name'],\n",
    "        }\n",
    "    f = open(file_path, 'rb')\n",
    "    data = []\n",
    "    # data_ = pickle.load(f)\n",
    "    cnt = 0\n",
    "    while True:\n",
    "        try:\n",
    "            data_ = pickle.load(f)\n",
    "            data_json = {\n",
    "                'id': data_['id'],\n",
    "                'label': data_['label'],\n",
    "                'project': data_['project'],\n",
    "                'bug_type': data_['bug_type'],\n",
    "                'label_source': data_['label_source'],\n",
    "            }\n",
    "\n",
    "            for key, value in data_['functions'].items():\n",
    "                if value['file'] == map_id[data_['id']]['file'] and value['name'] == map_id[data_['id']]['name']:\n",
    "                    data_json['function'] = value['code']\n",
    "                    break\n",
    "            data.append(data_json)\n",
    "        except EOFError:\n",
    "            break\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nginx 421\n",
      "openssl 8022\n",
      "ffmpeg 4826\n",
      "libtiff 553\n",
      "libav 4614\n",
      "httpd 217\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for dir_ in os.listdir(path):\n",
    "    if dir_[-3:] == '.gz' or dir_ in ['csvs', 'split']:\n",
    "        continue\n",
    "    dir__ = os.path.join(path, dir_)\n",
    "    extractor = get_file_path(dir__, key='extractor_0')\n",
    "    if len(extractor) == 0:\n",
    "        continue\n",
    "    label_0 = get_file_path(dir__, key='labeler_0')\n",
    "    label_1 = get_file_path(dir__, key='labeler_1')\n",
    "    \n",
    "    extractor_data = read_file_extractor(extractor[0], result[dir_]['label_1'])\n",
    "    result[dir_]['extractor_0'] = extractor_data\n",
    "    print(dir_, len(extractor_data))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_jsonl(folder_path, file_name, data_):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    f = open(file_path, 'w')\n",
    "    f.writelines([json.dumps(da)+\"\\n\"  for da in data_])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir_ in [\"libtiff\", \"httpd\", \"ffmpeg\", \"nginx\", \"openssl\", \"libav\"]:\n",
    "    next_path = os.path.join(path, 'jsonl', dir_)\n",
    "    if not os.path.exists(next_path):\n",
    "        os.makedirs(next_path)\n",
    "    write_to_jsonl(next_path, 'extractor_0.jsonl', result[dir_]['extractor_0'])\n",
    "    write_to_jsonl(next_path, 'labeler_0.jsonl', result[dir_]['label_0'])\n",
    "    write_to_jsonl(next_path, 'labeler_1.jsonl', result[dir_]['label_1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
